# New Data Pipeline Summary

## What Changed

### Old Approach (Single Step)
```
PDFs â†’ Direct Chunking â†’ Vector DB
```
- Hard to debug
- No visibility into raw data
- Difficult to create accurate test queries

### New Approach (Two Steps)
```
Step 1: PDFs â†’ JSON (raw data)
Step 2: JSON â†’ Chunks â†’ Vector DB
```
- Inspectable raw data
- Reproducible chunking
- Easy to create test queries with correct IDs

## New Scripts Created

### 1. `scripts/parse_pdfs_to_json.py`
Extracts all content from PDFs into structured JSON.

**Output:** `data/parsed_documents.json`

### 2. `scripts/create_chunks_from_json.py`
Creates chunks from JSON and builds vector database.

**Outputs:**
- `data/vector_db/` - FAISS database
- `data/vector_db/metadata.json` - DB info
- `data/vector_db/chunk_mapping.json` - **Key file for creating test queries!**

### 3. `scripts/run_full_pipeline.py`
Runs both steps automatically.

## How to Use

### Run Complete Pipeline
```bash
python scripts/run_full_pipeline.py
```

### With Custom Settings
```bash
python scripts/run_full_pipeline.py \
  --chunk_size 800 \
  --chunk_overlap 150
```

### Re-chunk Without Re-parsing
```bash
python scripts/run_full_pipeline.py --skip_parsing
```

## Key File: chunk_mapping.json

This file maps chunk indices to source documents:

```json
[
  {
    "chunk_index": 0,  â† Use this for test queries!
    "chunk_id": "document.pdf_chunk_0",
    "source_file": "document.pdf",
    "page": 0,
    "page_label": "1",
    "content_preview": "First 100 characters..."
  }
]
```

## Creating Accurate Test Queries

1. **Review chunk_mapping.json** to find content
2. **Note the chunk_index** of relevant chunks
3. **Update test_queries.json** with correct indices:

```json
{
  "query_id": 1,
  "query": "What is the EDD formula?",
  "relevant_docs": ["21", "22"],  â† Actual chunk_index values
  "query_type": "factual"
}
```

## Benefits

âœ… **Debuggable** - See raw extracted text before chunking
âœ… **Reproducible** - Re-chunk with different parameters
âœ… **Accurate** - Know exact chunk indices for evaluation
âœ… **Fast iteration** - Skip parsing when re-chunking

## Current Status

ğŸ”„ **PDF Parsing** - Running (45 PDFs)
â³ **Chunking** - Pending
â³ **Evaluation** - Pending

## Next Steps After Pipeline Completes

1. Check `data/parsed_documents.json` (raw data)
2. Review `data/vector_db/chunk_mapping.json`
3. Update test queries with correct chunk indices
4. Re-run evaluation
5. Test chatbot

## Files Structure

```
data/
â”œâ”€â”€ documents/              # Input PDFs
â”œâ”€â”€ parsed_documents.json   # â† Raw extracted data
â””â”€â”€ vector_db/
    â”œâ”€â”€ index.faiss        # Vector database
    â”œâ”€â”€ index.pkl
    â”œâ”€â”€ metadata.json
    â””â”€â”€ chunk_mapping.json # â† Use this for test queries!

scripts/
â”œâ”€â”€ parse_pdfs_to_json.py
â”œâ”€â”€ create_chunks_from_json.py
â”œâ”€â”€ run_full_pipeline.py
â””â”€â”€ README.md

evaluation/
â”œâ”€â”€ evaluate_retrieval.py
â”œâ”€â”€ README.md
â””â”€â”€ EVALUATION_SUMMARY.md
```

## Configuration Options

You switched to **qwen2.5:0.5b** for the LLM due to GPU memory constraints.
Fallback is set to **gemini-1.5-flash** if qwen fails.

### Embedding Model
Currently using: `sentence-transformers/all-mpnet-base-v2`

### Chunking Parameters
- Chunk size: 1000 tokens
- Chunk overlap: 200 tokens
- Strategy: Recursive text splitting

## Improvements Made

1. âœ… Removed Streamlit configuration UI â†’ Hardcoded in `CONFIG`
2. âœ… Added LLM fallback system (llama â†’ gemini)
3. âœ… Enhanced prompt for general conversation + RAG
4. âœ… Two-stage data pipeline for better control
5. âœ… Comprehensive evaluation framework
6. âœ… Chunk mapping for accurate test queries

## Documentation Created

- `scripts/README.md` - Pipeline usage
- `evaluation/README.md` - Metrics explanation
- `evaluation/EVALUATION_SUMMARY.md` - Current eval status
- `PIPELINE_SUMMARY.md` - This file

---

**Status:** Pipeline running. Once complete, you'll have full visibility into your data and can create accurate evaluations!
